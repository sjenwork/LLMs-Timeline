**Google發布T5模型**
時間：2020-10-20
Google發布T5 (Text-to-Text Transfer Transformer) 模型，統一了多任務訓練框架。

**核心創新：**

* 統一的「文本到文本」框架將所有NLP任務轉換為相同格式
* 基於標準的Encoder-Decoder Transformer架構
* 新的預訓練目標：跨度破壞(Span Corruption)
* 大規模、乾淨的預訓練數據集(C4)

**模型規格：**

* 多種參數規模，從Small到11B(110億)參數

**參考資料：**

* [研究論文](https://arxiv.org/abs/1910.10683)
* [Google AI Blog介紹](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)