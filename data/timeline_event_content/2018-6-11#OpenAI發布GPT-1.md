**OpenAI發布GPT-1**
時間：2018-6-11
OpenAI發布首個GPT模型，參數量約1.17億，是首個將Transformer與無監督預訓練結合的大型語言模型。

**核心特點：**

* 基於Transformer的12層Decoder-only架構
* 在BooksCorpus上進行無監督預訓練
* 通過預測下一個詞來學習語言模式
* 確立了「大規模無監督預訓練 + 特定任務微調」的技術路線

**參考資料：**

* [研究論文](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
* [OpenAI官方介紹](https://openai.com/index/language-unsupervised/)