{
    "title": {
        "media": {
            "url": "https://images.unsplash.com/photo-1620712943543-bcc4688e7485?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1740&q=80",
            "caption": "大型語言模型發展時間線",
            "credit": "AI Technology Evolution"
        },
        "text": {
            "headline": "大型語言模型發展時間線",
            "text": "<p>本時間線記錄了從2017年Transformer架構提出到2025年AI Agent技術崛起的重要里程碑。</p>"
        }
    },
    "events": [
        {
            "start_date": {
                "year": "2017",
                "month": "6",
                "day": "12"
            },
            "media": {
                "url": "https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png",
                "caption": "Transformer架構示意圖",
                "credit": "Google"
            },
            "text": {
                "headline": "Google發布Transformer架構",
                "text": "<p>Google在<i>arXiv</i>上發表論文《Attention Is All You Need》，提出了革命性的Transformer架構。</p><p><strong>核心創新：</strong></p><ul><li>完全基於注意力機制(Attention Mechanism)</li><li>摒棄了傳統循環神經網路(RNN)和卷積神經網路(CNN)的遞迴結構</li><li>實現並行計算，大幅提高訓練效率和模型性能</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://arxiv.org/abs/1706.03762' target='_blank'>原始論文</a></li><li><a href='https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html' target='_blank'>Google AI Blog介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2018",
                "month": "6",
                "day": "11"
            },
            "media": {
                "url": "https://pic.616pic.com/ys_img/00/58/25/Tq57QjfSmP.jpg",
                "caption": "GPT-1架構",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布GPT-1",
                "text": "<p>OpenAI發布首個GPT模型，參數量約1.17億，是首個將Transformer與無監督預訓練結合的大型語言模型。</p><p><strong>核心特點：</strong></p><ul><li>基於Transformer的12層Decoder-only架構</li><li>在BooksCorpus上進行無監督預訓練</li><li>通過預測下一個詞來學習語言模式</li><li>確立了「大規模無監督預訓練 + 特定任務微調」的技術路線</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf' target='_blank'>研究論文</a></li><li><a href='https://openai.com/index/language-unsupervised/' target='_blank'>OpenAI官方介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2018",
                "month": "10",
                "day": "11"
            },
            "media": {
                "url": "https://pic.616pic.com/ys_img/00/58/25/Tq57QjfSmP.jpg",
                "caption": "BERT預訓練與微調過程示意圖",
                "credit": "Google"
            },
            "text": {
                "headline": "Google發布BERT",
                "text": "<p>Google發布BERT (Bidirectional Encoder Representations from Transformers)，改進了雙向編碼表示，成為自然語言處理的重要里程碑。</p><p><strong>核心創新：</strong></p><ul><li>真正的雙向性，同時考慮詞語左右兩側的上下文</li><li>遮罩語言模型(MLM)預訓練任務</li><li>下一句預測(NSP)任務</li><li>基於Transformer的Encoder架構</li></ul><p><strong>模型規格：</strong></p><ul><li>BERT-Base: 12層Transformer編碼器，參數量約1.1億</li><li>BERT-Large: 24層Transformer編碼器，參數量約3.4億</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://arxiv.org/abs/1810.04805' target='_blank'>研究論文</a></li><li><a href='https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html' target='_blank'>Google AI Blog介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2019",
                "month": "2",
                "day": "14"
            },
            "media": {
                "url": "https://cdn.openai.com/research-covers/language-unsupervised/2x-no-mark.jpg",
                "caption": "GPT-2生成的文本示例",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布GPT-2",
                "text": "<p>OpenAI發布GPT-2，參數量達15億，質量明顯提升，但因安全考慮初期僅有限發布。</p><p><strong>核心進展：</strong></p><ul><li>參數規模擴大至15億</li><li>訓練數據更多樣化(WebText)</li><li>顯著提升文本生成質量和連貫性</li><li>展現出零樣本學習能力</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://openai.com/research/better-language-models' target='_blank'>OpenAI研究介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2020",
                "month": "5",
                "day": "28"
            },
            "media": {
                "url": "https://pic.616pic.com/ys_img/00/58/25/Tq57QjfSmP.jpg",
                "caption": "GPT-3架構示意圖",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布GPT-3",
                "text": "<p>OpenAI發布GPT-3，參數量達1750億，標誌著大型語言模型規模的重大飛躍，展現出上下文學習能力。</p><p><strong>核心突破：</strong></p><ul><li>參數規模達1750億，是當時最大的語言模型</li><li>強大的少樣本學習能力(Few-shot Learning)</li><li>上下文學習能力顯著提升</li><li>通過API商業化，開啟新的AI即服務模式</li></ul><p><strong>技術細節：</strong></p><ul><li>96層Transformer Decoder架構</li><li>訓練數據包括Common Crawl、WebText2、Books1、Books2和Wikipedia</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://arxiv.org/abs/2005.14165' target='_blank'>研究論文</a></li><li><a href='https://openai.com/research/gpt-3-apps' target='_blank'>OpenAI介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2020",
                "month": "10",
                "day": "20"
            },
            "media": {
                "url": "img/T5.jpg",
                "caption": "T5統一的文本到文本框架",
                "credit": "Google"
            },
            "text": {
                "headline": "Google發布T5模型",
                "text": "<p>Google發布T5 (Text-to-Text Transfer Transformer) 模型，統一了多任務訓練框架。</p><p><strong>核心創新：</strong></p><ul><li>統一的「文本到文本」框架將所有NLP任務轉換為相同格式</li><li>基於標準的Encoder-Decoder Transformer架構</li><li>新的預訓練目標：跨度破壞(Span Corruption)</li><li>大規模、乾淨的預訓練數據集(C4)</li></ul><p><strong>模型規格：</strong></p><ul><li>多種參數規模，從Small到11B(110億)參數</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://arxiv.org/abs/1910.10683' target='_blank'>研究論文</a></li><li><a href='https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html' target='_blank'>Google AI Blog介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2021",
                "month": "1",
                "day": "5"
            },
            "media": {
                "url": "img/Dall-E.webp",
                "caption": "DALL·E生成的圖像示例",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布DALL·E和CLIP",
                "text": "<p>OpenAI發布DALL·E和CLIP，分別用於圖像生成和圖文理解，標誌著多模態AI技術的重要進展。</p><p><strong>DALL·E特點：</strong></p><ul><li>基於GPT-3架構的變體</li><li>能夠從文本描述生成創意圖像</li><li>理解複雜的視覺概念和組合</li></ul><p><strong>CLIP特點：</strong></p><ul><li>Contrastive Language-Image Pre-training</li><li>學習圖像和文本之間的關係</li><li>零樣本遷移至各種視覺任務</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://openai.com/research/dall-e' target='_blank'>DALL·E介紹</a></li><li><a href='https://openai.com/research/clip' target='_blank'>CLIP介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2022",
                "month": "11",
                "day": "30"
            },
            "media": {
                "url": "img/ChatGPT.png",
                "caption": "ChatGPT界面示例",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布ChatGPT",
                "text": "<p>OpenAI發布ChatGPT，基於GPT-3.5系列，通過RLHF優化，提供更自然的對話體驗，標誌著生成式AI進入大眾視野。</p><p><strong>核心特點：</strong></p><ul><li>基於GPT-3.5系列模型</li><li>使用人類反饋強化學習(RLHF)進行優化</li><li>更好的指令遵循能力</li><li>有害內容生成的降低</li><li>對話能力的大幅提升</li></ul><p><strong>社會影響：</strong></p><ul><li>5天內用戶量突破百萬</li><li>成為歷史上增長最快的消費應用之一</li><li>推動了整個生成式AI行業的爆發</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://openai.com/blog/chatgpt' target='_blank'>OpenAI官方介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2023",
                "month": "3",
                "day": "14"
            },
            "media": {
                "url": "img/GPT4.jpg",
                "caption": "GPT-4性能對比圖",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布GPT-4",
                "text": "<p>OpenAI發布GPT-4，支持多模態輸入，能夠分析文本和圖像，推理能力和安全性顯著提升。</p><p><strong>核心突破：</strong></p><ul><li>支持多模態輸入，能夠理解和分析圖像</li><li>複雜推理能力大幅提升</li><li>上下文窗口擴展(初始為8K，後擴展至32K)</li><li>更強的指令遵循能力</li><li>在專業考試和基準測試上表現優異</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://openai.com/research/gpt-4' target='_blank'>OpenAI研究介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2023",
                "month": "12",
                "day": "6"
            },
            "media": {
                "url": "img/Gemini 1.0.jpg",
                "caption": "Gemini模型示意圖",
                "credit": "Google"
            },
            "text": {
                "headline": "Google發布Gemini 1.0系列",
                "text": "<p>Google發布Gemini 1.0系列，包括Ultra、Pro和Nano三個版本，是Google首個原生多模態大型語言模型。</p><p><strong>核心特點：</strong></p><ul><li>原生多模態設計(非模型拼接)</li><li>優化的Transformer解碼器架構</li><li>同時處理文本、圖像、音頻、視頻等多模態數據</li><li>大規模多任務訓練</li></ul><p><strong>版本規格：</strong></p><ul><li>Ultra: 最強大的版本，在多項基準測試上超越GPT-4</li><li>Pro: D平衡能力與效率的版本，用於Google Bard</li><li>Nano: 輕量級版本，可在移動設備上運行</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://blog.google/technology/ai/google-gemini-ai/' target='_blank'>Google官方介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2024",
                "month": "1",
                "day": "29"
            },
            "media": {
                "url": "img/Claude 3.jpg",
                "caption": "Claude 3系列模型示意圖",
                "credit": "Anthropic"
            },
            "text": {
                "headline": "Anthropic發布Claude 3系列",
                "text": "<p>Anthropic發布Claude 3系列，包括Haiku、Sonnet和Opus三個版本，在多個基準測試中表現卓越。</p><p><strong>核心特點：</strong></p><ul><li>首次支持圖像輸入的多模態能力</li><li>視覺推理顯著增強</li><li>更低的幻覺率</li><li>更強的問題解決能力</li></ul><p><strong>版本規格：</strong></p><ul><li>Opus: 最強大版本，性能超越大多數競爭模型</li><li>Sonnet: 平衡性能與速度的中等版本</li><li>Haiku: 快速輕量版本，適合高性能需求場景</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://www.anthropic.com/news/claude-3-family' target='_blank'>Anthropic官方介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2024",
                "month": "2",
                "day": "15"
            },
            "media": {
                "url": "img/Gemini 1.5 Pro.png",
                "caption": "Gemini 1.5 Pro超長上下文示意圖",
                "credit": "Google"
            },
            "text": {
                "headline": "Google發布Gemini 1.5 Pro",
                "text": "<p>Google發布Gemini 1.5 Pro，提供100萬令牌的上下文窗口，建立了長上下文處理的新標準。</p><p><strong>核心突破：</strong></p><ul><li>超長上下文窗口：支持100萬令牌的上下文處理</li><li>視頻理解增強：能夠處理和理解長視頻內容</li><li>代碼處理能力提升：可以分析和理解大型代碼庫</li></ul><p><strong>架構改進：</strong></p><ul><li>混合注意力機制(可能採用稀疏注意力技術)</li><li>更高效的上下文壓縮方法</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://blog.google/technology/ai/google-gemini-1-5-pro-availability/' target='_blank'>Google官方介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2024",
                "month": "5",
                "day": "14"
            },
            "media": {
                "url": "img/gpt-4o.png",
                "caption": "GPT-4o多模態能力示例",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布GPT-4o",
                "text": "<p>OpenAI發布GPT-4o ('o' for 'omni')，進一步強化多模態處理能力，響應速度更快，用戶體驗更自然。</p><p><strong>核心特性：</strong></p><ul><li>強化的多模態處理能力(文本、圖像、音頻)</li><li>大幅提升的響應速度</li><li>更自然的對話體驗</li><li>實時語音交互和視覺理解能力</li></ul><p><strong>參考資料：</strong></p><ul><li><a href='https://openai.com/blog/gpt-4o' target='_blank'>OpenAI官方介紹</a></li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2024",
                "month": "11",
                "day": "15"
            },
            "media": {
                "url": "img/MCP.png",
                "caption": "MCP架構示意圖",
                "credit": "Anthropic"
            },
            "text": {
                "headline": "Anthropic發布Model Context Protocol (MCP)",
                "text": "<p>Anthropic發布Model Context Protocol (MCP)，為AI系統提供統一標準，使模型能夠安全訪問工具和外部數據。</p><p><strong>MCP核心定義：</strong></p><ul><li>一個開放標準，定義應用程序如何向大型語言模型提供結構化上下文</li><li>創建模型與外部工具、API和數據源之間的安全雙向連接</li></ul><p><strong>MCP工作原理：</strong></p><ul><li>MCP主機：作為中央樞紐的應用程序</li><li>MCP服務器：暴露特定功能的服務</li><li>MCP客戶端：通常是由語言模型驅動的應用程序</li><li>數據源連接：本地和遠程數據源的標準訪問方式</li></ul><p><strong>行業意義：</strong></p><ul><li>開創了Agent發展的新階段</li><li>建立AI工具使用的共同標準</li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2025",
                "month": "1",
                "day": "23"
            },
            "media": {
                "url": "img/openAI Operator.webp",
                "caption": "OpenAI Operator示意圖",
                "credit": "OpenAI"
            },
            "text": {
                "headline": "OpenAI發布Operator",
                "text": "<p>OpenAI發布Operator，由Computer-Using Agent (CUA)驅動，成為OpenAI發布的第一個AI Agent。</p><p><strong>核心技術：</strong></p><ul><li>Computer-Using Agent (CUA)</li></ul><p><strong>關鍵能力：</strong></p><ul><li>能夠自主使用計算機執行任務</li><li>網頁瀏覽和交互</li><li>文件操作和數據處理</li><li>完成複雜的多步驟任務</li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2025",
                "month": "2",
                "day": "14"
            },
            "media": {
                "url": "img/Claude 3.7 Sonnet.webp",
                "caption": "Claude 3.7 Sonnet思考模式示意圖",
                "credit": "Anthropic"
            },
            "text": {
                "headline": "Anthropic發布Claude 3.7 Sonnet",
                "text": "<p>Anthropic發布Claude 3.7 Sonnet，引入混合推理方法，在單一系統中結合快速響應和更深入的逐步思考。</p><p><strong>關鍵創新：</strong></p><ul><li>混合推理(Hybrid Reasoning)</li><li>結合快速、直覺式反應(System 1)與深度、逐步思考(System 2)</li><li>在處理複雜問題時能夠切換到更深入的推理模式</li><li>被用戶稱為思考模式(Thinking Mode)</li></ul><p><strong>能力提升：</strong></p><ul><li>程式碼理解和生成能力顯著增強</li><li>複雜問題解決能力提升</li><li>更透明的推理過程展示</li></ul>"
            }
        },
        {
            "start_date": {
                "year": "2025",
                "month": "4",
                "day": "9"
            },
            "media": {
                "url": "img/A2A.png",
                "caption": "A2A協議架構示意圖",
                "credit": "Google"
            },
            "text": {
                "headline": "Google發布Agent-to-Agent (A2A)協議",
                "text": "<p>Google發布Agent-to-Agent (A2A)協議，用於AI代理之間的直接通信，與MCP形成互補關係。</p><p><strong>A2A關鍵特性：</strong></p><ul><li>代理發現：通過AgentCard機制讓代理互相發現</li><li>任務協調：支持從快速操作到長時間運行的流程</li><li>安全協作：具有企業級身份驗證</li><li>基於任務的狀態管理</li></ul><p><strong>與MCP的關係：</strong></p><ul><li>A2A專注於代理之間的通信</li><li>MCP專注於代理與工具的連接</li><li>兩者形成互補關係</li></ul><p><strong>行業意義：</strong></p><ul><li>Google同時宣布支持Anthropic的MCP協議</li><li>推動行業標準形成</li><li>展示大型AI公司在標準方面的合作</li></ul>"
            }
        }
    ]
} 